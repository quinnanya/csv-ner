{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition in CSVs\n",
    "\n",
    "This notebook uses [Spacy](https://spacy.io/) to perform named-entity recognition on text in specified columns of a CSV file. The notebook adds new columns to the CSV with the identified entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load core modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os is used to change the directory\n",
    "import os\n",
    "#spacy is used for the NER\n",
    "import spacy\n",
    "#pandas is used to read, edit, and write tabular data\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Download and load language-specific data\n",
    "This notebook was originally created for German text, but you can substitute values in the following two cells with the corresponding ones for [another language that Spacy supports](https://spacy.io/models). Choose the language you'd like, and check the box for \"import as module\" on the Spacy site to see the values for the language you'd like to use.\n",
    "\n",
    "For instance, to use Lithuanian, you'd change the first code cell below to: `!python -m spacy download lt_core_news_sm` \n",
    "\n",
    "and the second one to: \n",
    "\n",
    "`import lt_core_news_sm\n",
    "snlp = spacy.load(\"import lt_core_news_sm\")`\n",
    "\n",
    "After you've run the first code cell once ever on the computer where you're running this notebook, you can skip it and just run the cell that imports the module. There's no harm in running the first cell again, but it won't do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloads the model for the specified language (German)\n",
    "!python -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the model as a module\n",
    "import de_core_news_md\n",
    "#loads the model as snlp\n",
    "snlp = spacy.load(\"de_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Specify file directory and file\n",
    "Replace `/Users/qad/Documents/netzdg` with the full path to the directory that has your input CSV file. This is also the directory where your output CSV file will be saved.\n",
    "\n",
    "The syntax for the path is different on Mac and Windows. For instance, the default path to the Documents directory is (substituting your user name on the computer for YOUR-USER-NAME):\n",
    "\n",
    "- On Mac: '/Users/YOUR-USER-NAME/Documents'\n",
    "- On Windows: 'C:\\\\\\Users\\\\\\YOUR-USER-NAME\\\\\\Documents'\n",
    "\n",
    "Then, replace `netzdg_blog.csv` with the name of a CSV file in the directory you've specified. The first row of the CSV file should be a header (i.e. with the name of each column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcefiledirectory = '/Users/qad/Documents/netzdg'\n",
    "#changes the working directory to the directory specified above\n",
    "os.chdir(sourcefiledirectory)\n",
    "infilename = 'netzdg_blog.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Reading CSV, NER, writing CSV\n",
    "This step actually processes your data. \n",
    "\n",
    "In this example, there are two columns in the source file that contain text where we want to find entities: *text* and *comments*. \n",
    "\n",
    "The cell below reads in the data from the CSV file you've specified above. It creates two new columns: *ner_text* which includes the entities extracted from the *text* column, and *ner_comments* with the entities from the *comments* column.\n",
    "\n",
    "If you want to do NER on columns with different names in your source CSV, change *text* and *comments* to match the appropriate header in your source CSV. You may also want to change *ner_text* and *ner_comments* to something more informative for your data set as well. If you want to do this on more than two columns in your source CSV, you can add additional lines following the same model. If you want to do it on only one column, delete one of the sets of lines.\n",
    "\n",
    "The `print(df['ner_text'])` and `print(df['ner_comments'])` commands are optional, but are a convenient way for you to get a sense of what the output will be. When the values are printed, each term is surrounded by parentheses (), and all the entities for a given row of the CSV are surrounded by square brackets \\[\\]. When you *print* the output, multi-word entities are separated by commas within the parentheses (such as: (Europäische, Union)), but when you *write* it to a new CSV file, the parentheses and commas between individual words disappear, and you'll just get a single comma-separated list inside of square brackets, with commas representing individual entities (e.g. \\[Uploadfilter, Europäische Union\\]).\n",
    "\n",
    "The final cell specifies an output name for the CSV file the notebook will generate, including all the original cells of the original CSV, plus the new ones you've created with the extracted entities. It's set up to prefix the name of the original CSV with `ner_`, but you can change it to something else if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates pandas dataframe with your specified input file, using the first row as a header\n",
    "df = pd.read_csv(infilename, header=0)\n",
    "#creates a new column, ner_text, with entities extracted from a column titled 'text'\n",
    "df['ner_text'] = df['text'].astype(str).apply(lambda x: list(snlp(x).ents))\n",
    "#prints the values from ner_text\n",
    "print(df['ner_text'])\n",
    "#creates a new column, ner_comments, with entities extracted from a column titled 'comments'\n",
    "df['ner_comments'] = df['comments'].astype(str).apply(lambda x: list(snlp(x).ents))\n",
    "#prints the values from ner_comments\n",
    "print(df['ner_comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = 'ner_'+infilename\n",
    "df.to_csv(outfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested citation\n",
    "If you use this notebook as part of your project workflow, you can cite it with something to the effect of:\n",
    "\n",
    "Dombrowski, Quinn. *Named entity recognition in CSVs* Jupyter notebook. https://github.com/quinnanya/csv-ner. 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
